{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import re\n",
    "import collections\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 : 마케팅 연애의목적 0.0043\n",
      "20000 : 콘텐츠 스포티비 기자회견장에서 화보 찍는 체조요정들 0.0071\n",
      "30000 : 뉴스 스브스뉴스 스토리카드 그 사람이 사랑하는 방법 0.0128\n",
      "40000 : 뉴스 엑스트라계의 최수종 갓스트라 스브스뉴스 스토리카드  0.0071\n",
      "50000 : 콘텐츠 따뜻한 커피도 체온을 떨어뜨린다  동영상  0.0073\n",
      "총 라인 수 :  51850\n",
      "타이틀 수 :  51826\n",
      "CTR 수 :  51826\n",
      "에러 수 :  24\n",
      "['콘텐츠 보그걸 초강력 워터프루프', '콘텐츠 보그걸 셔츠 초간단 연출법', '콘텐츠 보그걸 센스 넘치는 여행 소품들', '콘텐츠 보그걸 부위별 셀프 운동법', '마케팅 중복이벤트']\n",
      "[[0.0211], [0.0144], [0.0091], [0.0209], [0.0072]]\n"
     ]
    }
   ],
   "source": [
    "#file load\n",
    "\n",
    "f = open('data/content_list.csv','r')\n",
    "line_counter = 0\n",
    "unsupport_title_counter = 0\n",
    "title_arr = []\n",
    "ctr_arr = []\n",
    "\n",
    "ex_hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "def map_hangul(str):\n",
    "    str = str.replace('_',' ')\n",
    "    str = ex_hangul.sub('',str)\n",
    "    str = str.replace('  ',' ')\n",
    "    return str\n",
    "\n",
    "while True:    \n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    line_counter += 1\n",
    "    \n",
    "    line = line.replace('\"\"',' ')\n",
    "    content_info = line.split('\"')\n",
    "    \n",
    "    try:\n",
    "        title = map_hangul(content_info[1])\n",
    "        ctr = content_info[2].split(',')[1]\n",
    "        title_arr.append(title)\n",
    "        ctr_arr.append([float(ctr)])\n",
    "        if line_counter % 10000 == 0:\n",
    "            print(line_counter, \":\", title, ctr)\n",
    "    except:\n",
    "        unsupport_title_counter += 1\n",
    "        \n",
    "print('총 라인 수 : ', line_counter)\n",
    "print('타이틀 수 : ', len(title_arr))\n",
    "print('CTR 수 : ', len(ctr_arr))\n",
    "print('에러 수 : ',unsupport_title_counter)\n",
    "    \n",
    "print(title_arr[:5])\n",
    "print(ctr_arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "filename_queue = tf.train.string_input_producer([\"data/content_list.csv\"])\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "batch = tf.train.batch([value], batch_size=10)\n",
    "with tf.Session() as sess:\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    v = sess.run(batch)\n",
    "    print(len(v))\n",
    "\n",
    "#     print(v[0].decode('utf-8'))\n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#file load\n",
    "\n",
    "f = open('data/content_list.csv','r')\n",
    "line_counter = 0\n",
    "unsupport_title_counter = 0\n",
    "title_arr = []\n",
    "ctr_arr = []\n",
    "\n",
    "ex_hangul = re.compile('[^ ㄱ-ㅣ가-힣]+') # 한글과 띄어쓰기를 제외한 모든 글자\n",
    "def map_hangul(str):\n",
    "    str = str.replace('_',' ')\n",
    "    str = ex_hangul.sub('',str)\n",
    "    str = str.replace('  ',' ')\n",
    "    return str\n",
    "\n",
    "while True:    \n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    line_counter += 1\n",
    "    \n",
    "    line = line.replace('\"\"',' ')\n",
    "    content_info = line.split('\"')\n",
    "    \n",
    "    try:\n",
    "        title = map_hangul(content_info[1])\n",
    "        ctr = content_info[2].split(',')[1]\n",
    "        title_arr.append(title)\n",
    "        ctr_arr.append([float(ctr)])\n",
    "        if line_counter % 10000 == 0:\n",
    "            print(line_counter, \":\", title, ctr)\n",
    "    except:\n",
    "        unsupport_title_counter += 1\n",
    "        \n",
    "print('총 라인 수 : ', line_counter)\n",
    "print('타이틀 수 : ', len(title_arr))\n",
    "print('CTR 수 : ', len(ctr_arr))\n",
    "print('에러 수 : ',unsupport_title_counter)\n",
    "    \n",
    "print(title_arr[:5])\n",
    "print(ctr_arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random_x = []\n",
    "for i in range(len(ctr_arr)):\n",
    "    random_x.append(random.randrange(1,10000))\n",
    "\n",
    "plt.figure(num=None, figsize=(20, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.plot(ctr_arr, random_x, 'ro', alpha=0.01)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ctr에 grade를 매긴다\n",
    "grade = [0,0,0,0,0,0]\n",
    "ctr_grade_arr = []\n",
    "for ctr in ctr_arr:\n",
    "    if ctr[0] < 0.005:\n",
    "        grade[0] += 1\n",
    "        ctr_grade_arr.append([1.0,0.0,0.0,0.0,0.0,0.0])\n",
    "    elif ctr[0] >= 0.005 and ctr[0] < 0.01:\n",
    "        grade[1] += 1\n",
    "        ctr_grade_arr.append([0.0,1.0,0.0,0.0,0.0,0.0])\n",
    "    elif ctr[0] >= 0.01 and ctr[0] < 0.015:\n",
    "        grade[2] += 1\n",
    "        ctr_grade_arr.append([0.0,0.0,1.0,0.0,0.0,0.0])\n",
    "    elif ctr[0] >= 0.015 and ctr[0] < 0.02:\n",
    "        grade[3] += 1\n",
    "        ctr_grade_arr.append([0.0,0.0,0.0,1.0,0.0,0.0])\n",
    "    elif ctr[0] >= 0.02 and ctr[0] < 0.025:\n",
    "        grade[4] += 1\n",
    "        ctr_grade_arr.append([0.0,0.0,0.0,0.0,1.0,0.0])\n",
    "    elif ctr[0] >= 0.025:\n",
    "        grade[5] += 1\n",
    "        ctr_grade_arr.append([0.0,0.0,0.0,0.0,0.0,1.0])\n",
    "print(grade)\n",
    "print(ctr_grade_arr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#dictionary를 만들기위해 단어만 주욱 모은다\n",
    "words = functools.reduce(lambda x,y: x+' '+y, title_arr).split(' ')\n",
    "print(len(words))\n",
    "print(words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary_size = 60000\n",
    "\n",
    "count = [['UNK', -1]] #unknown\n",
    "count.extend(collections.Counter(words).most_common(vocabulary_size - 1))\n",
    "print(len(count))\n",
    "print(count[:20])\n",
    "\n",
    "#dictionary 정의 & feeding\n",
    "dictionary = dict()\n",
    "for word, _ in count:\n",
    "    dictionary[word] = len(dictionary) #여기서 word는 count를 돌린거라서 유니크함\n",
    "print(len(dictionary))\n",
    "\n",
    "unk_count = 0\n",
    "\n",
    "#unknown counting\n",
    "for word in words:\n",
    "    if word not in dictionary:\n",
    "        unk_count += 1\n",
    "    \n",
    "#title_arr 를 index값으로 title_vector_arr로 변환\n",
    "title_vector_arr = []\n",
    "for title in title_arr:\n",
    "    title_vector = []\n",
    "    word_arr = title.split(' ')\n",
    "    for word in word_arr:\n",
    "        if word in dictionary:\n",
    "            index = dictionary[word]\n",
    "        else:\n",
    "            index = 0\n",
    "        title_vector.append(index)\n",
    "    title_vector_arr.append(title_vector)\n",
    "    \n",
    "count[0][1] = unk_count\n",
    "reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "\n",
    "# del words  # Hint to reduce memory.\n",
    "print('Most common words (+UNK)', count[:5])\n",
    "print('Title vector array sample', title_vector_arr[:10])\n",
    "for title_vector in title_vector_arr[:10]:\n",
    "    print('Reverse dict', [reverse_dictionary[word_index] for word_index in title_vector])\n",
    "print(len(title_vector_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# max_length = 0\n",
    "# for title_vector in title_vector_arr:\n",
    "#     if max_length < len(title_vector):\n",
    "#         max_length = len(title_vector)\n",
    "# print(max_length)\n",
    "\n",
    "max_length = 10\n",
    "#vector 사이즈를 정의하고, 부족한 부분은 empty_index로 채워서 사이즈를 맞춘다\n",
    "empty_index = -1\n",
    "title_vector_size = max_length\n",
    "index = 0\n",
    "for title_vector in title_vector_arr:\n",
    "    while(len(title_vector) < title_vector_size):\n",
    "        title_vector.append(empty_index)\n",
    "    title_vector_arr[index] = title_vector[0:max_length]\n",
    "    index +=1\n",
    "print('Title vector array sample', title_vector_arr[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def xavier_init(n_inputs, n_outputs):\n",
    "    init_range = tf.sqrt(6.0/(n_inputs+n_outputs))\n",
    "    return tf.random_uniform_initializer(-init_range, init_range)\n",
    "\n",
    "grade_size = len(grade)\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(51826, title_vector_size), name='title_vector_arr')\n",
    "Y = tf.placeholder(tf.float32, shape=(51826, grade_size), name='ctr_grade_arr')\n",
    "\n",
    "neuron_width = 200\n",
    "W1 = tf.get_variable(shape=[title_vector_size, neuron_width], initializer=xavier_init(title_vector_size, neuron_width), name='hidden1')\n",
    "W2 = tf.get_variable(shape=[neuron_width, neuron_width], initializer=xavier_init(neuron_width, neuron_width), name='hidden2')\n",
    "W3 = tf.get_variable(shape=[neuron_width, neuron_width], initializer=xavier_init(neuron_width, neuron_width), name='hidden3')\n",
    "W4 = tf.get_variable(shape=[neuron_width, grade_size], initializer=xavier_init(neuron_width, grade_size), name='hidden4')\n",
    "\n",
    "b1 = tf.Variable(tf.zeros([neuron_width]), name='bias1')\n",
    "b2 = tf.Variable(tf.zeros([neuron_width]), name='bias2')\n",
    "b3 = tf.Variable(tf.zeros([neuron_width]), name='bias3')\n",
    "b4 = tf.Variable(tf.zeros([grade_size]), name='bias4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "L2 = tf.nn.softmax(tf.matmul(X, W1) + b1)\n",
    "L3 = tf.nn.softmax(tf.matmul(L2, W2) + b2)\n",
    "L4 = tf.nn.softmax(tf.matmul(L3, W3) + b3)\n",
    "h = tf.matmul(L4, W4) + b4\n",
    "# h = tf.matmul(L2, W3) + b3\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=h, labels=Y, name='cost'))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(h,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sample_cost = 0\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for step in range(5000):\n",
    "        sess.run(optimizer, feed_dict={X: title_vector_arr, Y: ctr_grade_arr})\n",
    "        sample_cost = sess.run(cost, feed_dict={X: title_vector_arr, Y: ctr_grade_arr})\n",
    "        acc= sess.run(accuracy, feed_dict={X: title_vector_arr, Y: ctr_grade_arr})\n",
    "        h_sample= sess.run(h, feed_dict={X: title_vector_arr, Y: ctr_grade_arr})\n",
    "        if step % 10 == 0:\n",
    "            print(step,':', acc)\n",
    "            print(h_sample[1])\n",
    "            print('-------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_index=9876\n",
    "print(title_arr[sample_index])\n",
    "print(title_vector_arr[sample_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
